dataset:
  name: cifar_100
  root: ~/datasets/cifar
  train:
    split: train
  val:
    split: test
  resize: 224

training:
  train_epochs: 240
  print_interval: 20
  val_interval: 1000
  batch_size: 64
  num_workers: 16
  sync_bn: True
  pre_train: run/unpack_mutual_cifar100/vit.pth
  use_train: False

model:
  name: vit
  transformer:
    embed_dim: 288
    num_encoder_layers: 6
    num_heads: 9
    dim_feedforward: 1152   # embed_dim * 4
    dropout: 0.1
    activation: gelu
    final_norm: True
  patch_embed:
    name: vit_like
    img_size: 224
    patch_size: 16
    image_channels: 3
  pos_encoding:
    name: learnable
    dropout: null

plot:
  direction:
    norm: filter
    ignore: bias_bn
  coordinate:
    x_axis:
      start: -1
      end: 1
      steps: 21
    y_axis:
      start: -1
      end: 1
      steps: 21
  cfg:
    levels: 5
    vtp_cfg:
      z_err_max: -1
      z_loss_max: 1.0e+9
      normalize_loss: -1
      num_interpolate_points: -1
      show_points: True
      show_polys: True

loss:
  name: ce_loss
  weight_dict:
    cls: 1.0
  
